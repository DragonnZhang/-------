#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„é—®é¢˜æ–‡ç« ç»Ÿè®¡å’Œä¿®å¤æµ‹è¯•
"""

import json
import os
from pathlib import Path

def count_problematic_articles():
    """ç»Ÿè®¡é—®é¢˜æ–‡ç« æ•°é‡"""
    articles_dir = Path("articles")
    problematic_count = 0
    total_count = 0
    problematic_details = []
    
    for date_dir in articles_dir.iterdir():
        if not date_dir.is_dir():
            continue
            
        for article_file in date_dir.glob("*.json"):
            total_count += 1
            try:
                with open(article_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                content = data.get('content', {})
                title = content.get('title', '')
                article_content = content.get('content', '')
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é—®é¢˜æ–‡ç« 
                is_problematic = (
                    title == '491 Forbidden' or
                    article_content == 'æ— å†…å®¹' or
                    '491 Forbidden' in title or
                    len(article_content) < 50
                )
                
                if is_problematic:
                    problematic_count += 1
                    metadata = data.get('metadata', {})
                    problematic_details.append({
                        'date': date_dir.name,
                        'file': article_file.name,
                        'title': metadata.get('mainTitle', 'æœªçŸ¥'),
                        'content_length': len(article_content)
                    })
                    
            except Exception as e:
                print(f"è¯»å–å¤±è´¥: {article_file} - {e}")
    
    return total_count, problematic_count, problematic_details

def main():
    print("æ­£åœ¨ç»Ÿè®¡é—®é¢˜æ–‡ç« ...")
    
    total, problematic, details = count_problematic_articles()
    
    print(f"\\nç»Ÿè®¡ç»“æœ:")
    print(f"æ€»æ–‡ç« æ•°: {total}")
    print(f"é—®é¢˜æ–‡ç« æ•°: {problematic}")
    print(f"æˆåŠŸç‡: {((total - problematic) / total * 100):.1f}%")
    
    if problematic > 0:
        print(f"\\nå‰10ä¸ªé—®é¢˜æ–‡ç« :")
        for i, detail in enumerate(details[:10], 1):
            print(f"{i:2d}. {detail['date']}: {detail['title']} (å†…å®¹é•¿åº¦: {detail['content_length']})")
        
        if len(details) > 10:
            print(f"    ... è¿˜æœ‰ {len(details) - 10} ç¯‡é—®é¢˜æ–‡ç« ")
            
        print(f"\\nâœ… è§£å†³æ–¹æ¡ˆçŠ¶æ€:")
        print("1. âœ… å®ç”¨çˆ¬è™«å·²å¼€å‘å®Œæˆå¹¶æµ‹è¯•æˆåŠŸ")
        print("2. âœ… æˆåŠŸä¿®å¤äº†ä¸€ç¯‡æµ‹è¯•æ–‡ç«  (20250520_001_02_2642)")
        print("3. âœ… åçˆ¬è™«ç»•è¿‡ç­–ç•¥æœ‰æ•ˆï¼ˆä½¿ç”¨æ›´é•¿å»¶è¿Ÿå’ŒçœŸå®è¯·æ±‚å¤´ï¼‰")
        print("4. ğŸ”„ éœ€è¦ç»§ç»­æ‰¹é‡ä¿®å¤å‰©ä½™é—®é¢˜æ–‡ç« ")
        
        print(f"\\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
        print("1. ä½¿ç”¨ practical_crawler.py é€ä¸ªä¿®å¤é‡è¦æ–‡ç« ")
        print("2. è®¾ç½®åˆç†çš„å»¶è¿Ÿï¼ˆ15-30ç§’ï¼‰é¿å…è§¦å‘åçˆ¬è™«")
        print("3. åˆ†æ‰¹æ¬¡å¤„ç†ï¼Œæ¯æ¬¡å¤„ç†5-10ç¯‡æ–‡ç« ")
        print("4. å®šæœŸæ£€æŸ¥ä¿®å¤æ•ˆæœ")
    else:
        print("\\nğŸ‰ æ‰€æœ‰æ–‡ç« éƒ½å·²æˆåŠŸçˆ¬å–ï¼")

if __name__ == "__main__":
    main()
