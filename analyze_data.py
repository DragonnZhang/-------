#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ†æå’ŒéªŒè¯è„šæœ¬
åˆ†æå·²ä¸‹è½½çš„äººæ°‘é‚®ç”µæŠ¥æ•°æ®
"""

import json
import os
from pathlib import Path
from collections import defaultdict
import pandas as pd

def analyze_downloaded_data():
    """åˆ†æå·²ä¸‹è½½çš„æ•°æ®"""
    data_dir = Path("data")
    
    print("=== äººæ°‘é‚®ç”µæŠ¥æ•°æ®åˆ†ææŠ¥å‘Š ===\n")
    
    # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
    json_files = list(data_dir.glob("*.json"))
    print(f"ğŸ“ æ€»å…±ä¸‹è½½æ–‡ä»¶æ•°: {len(json_files)}")
    
    total_articles = 0
    date_stats = {}
    column_stats = defaultdict(int)
    author_stats = defaultdict(int)
    word_count_stats = []
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    for json_file in sorted(json_files):
        date_str = json_file.stem.replace("_data", "")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list) and len(data) > 0:
                # æå–æ–‡ç« ä¿¡æ¯
                articles = []
                for item in data:
                    if 'onePageArticleList' in item:
                        articles.extend(item['onePageArticleList'])
                
                article_count = len(articles)
                date_stats[date_str] = article_count
                total_articles += article_count
                
                # ç»Ÿè®¡æ ç›®å’Œä½œè€…
                for article in articles:
                    if article.get('articleColumn'):
                        column_stats[article['articleColumn']] += 1
                    if article.get('articleAuthor'):
                        author_stats[article['articleAuthor']] += 1
                    if article.get('wordNumber'):
                        word_count_stats.append(article['wordNumber'])
                
                print(f"ğŸ“… {date_str}: {article_count} ç¯‡æ–‡ç« ")
            else:
                print(f"âš ï¸  {date_str}: æ•°æ®æ ¼å¼å¼‚å¸¸")
                
        except Exception as e:
            print(f"âŒ {json_file.name}: æ–‡ä»¶è¯»å–å¤±è´¥ - {e}")
    
    print(f"\nğŸ“Š **æ€»ä½“ç»Ÿè®¡**")
    print(f"   æ€»æ–‡ç« æ•°: {total_articles}")
    print(f"   å¹³å‡æ¯æ—¥æ–‡ç« æ•°: {total_articles/len(date_stats):.1f}")
    
    # å­—æ•°ç»Ÿè®¡
    if word_count_stats:
        print(f"   å¹³å‡å­—æ•°: {sum(word_count_stats)/len(word_count_stats):.0f}")
        print(f"   æœ€é•¿æ–‡ç« : {max(word_count_stats)} å­—")
        print(f"   æœ€çŸ­æ–‡ç« : {min(word_count_stats)} å­—")
    
    # çƒ­é—¨æ ç›®
    print(f"\nğŸ“° **çƒ­é—¨æ ç›® (Top 10)**")
    for column, count in sorted(column_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        if column.strip():  # æ’é™¤ç©ºæ ç›®
            print(f"   {column}: {count} ç¯‡")
    
    # æ´»è·ƒä½œè€…
    print(f"\nâœï¸  **æ´»è·ƒä½œè€… (Top 10)**")
    for author, count in sorted(author_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        if author.strip() and not author.startswith("è®°è€…"):  # æ’é™¤ç©ºä½œè€…å’Œé€šç”¨è®°è€…
            print(f"   {author}: {count} ç¯‡")
    
    # ç¼ºå¤±æ—¥æœŸåˆ†æ
    print(f"\nğŸ“… **æ•°æ®è¦†ç›–æƒ…å†µ**")
    all_may_dates = [f"202505{i:02d}" for i in range(1, 32)]
    downloaded_dates = set(date_stats.keys())
    missing_dates = set(all_may_dates) - downloaded_dates
    
    print(f"   å·²ä¸‹è½½æ—¥æœŸ: {len(downloaded_dates)} å¤©")
    print(f"   ç¼ºå¤±æ—¥æœŸ: {len(missing_dates)} å¤©")
    
    if missing_dates:
        missing_sorted = sorted(missing_dates)
        print(f"   ç¼ºå¤±çš„å…·ä½“æ—¥æœŸ: {', '.join(missing_sorted)}")
        
        # åˆ†æç¼ºå¤±æ—¥æœŸæ˜¯å¦ä¸ºå‘¨æœ«
        from datetime import datetime
        weekend_missing = []
        weekday_missing = []
        
        for date_str in missing_sorted:
            try:
                date_obj = datetime.strptime(date_str, "%Y%m%d")
                if date_obj.weekday() >= 5:  # å‘¨å…­=5, å‘¨æ—¥=6
                    weekend_missing.append(date_str)
                else:
                    weekday_missing.append(date_str)
            except:
                pass
        
        if weekend_missing:
            print(f"   å…¶ä¸­å‘¨æœ«: {len(weekend_missing)} å¤© ({', '.join(weekend_missing)})")
        if weekday_missing:
            print(f"   å…¶ä¸­å·¥ä½œæ—¥: {len(weekday_missing)} å¤© ({', '.join(weekday_missing)})")
    
    return date_stats, total_articles

def export_article_list():
    """å¯¼å‡ºæ–‡ç« æ¸…å•åˆ°CSV"""
    data_dir = Path("data")
    json_files = list(data_dir.glob("*.json"))
    
    all_articles = []
    
    for json_file in sorted(json_files):
        date_str = json_file.stem.replace("_data", "")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                for item in data:
                    if 'onePageArticleList' in item:
                        for article in item['onePageArticleList']:
                            article_info = {
                                'date': date_str,
                                'title': article.get('mainTitle', ''),
                                'author': article.get('articleAuthor', ''),
                                'column': article.get('articleColumn', ''),
                                'word_count': article.get('wordNumber', 0),
                                'issue_number': article.get('issueNumber', ''),
                                'href': article.get('articleHref', '')
                            }
                            all_articles.append(article_info)
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {json_file.name} æ—¶å‡ºé”™: {e}")
    
    if all_articles:
        df = pd.DataFrame(all_articles)
        csv_file = "article_list.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ å·²å¯¼å‡ºæ–‡ç« æ¸…å•åˆ°: {csv_file}")
        print(f"   æ€»å…± {len(all_articles)} ç¯‡æ–‡ç« ")
        return csv_file
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡ç« æ•°æ®")
        return None

def validate_data_integrity():
    """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
    print("\nğŸ” **æ•°æ®å®Œæ•´æ€§æ£€æŸ¥**")
    
    data_dir = Path("data")
    json_files = list(data_dir.glob("*.json"))
    
    valid_files = 0
    invalid_files = 0
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            if isinstance(data, list):
                has_articles = False
                for item in data:
                    if isinstance(item, dict) and 'onePageArticleList' in item:
                        articles = item['onePageArticleList']
                        if isinstance(articles, list) and len(articles) > 0:
                            # æ£€æŸ¥æ–‡ç« å­—æ®µå®Œæ•´æ€§
                            for article in articles:
                                required_fields = ['mainTitle', 'articleIssueDate', 'articleHref']
                                if all(field in article for field in required_fields):
                                    has_articles = True
                                    break
                        if has_articles:
                            break
                
                if has_articles:
                    print(f"âœ… {json_file.name}: æ•°æ®ç»“æ„æ­£ç¡®")
                    valid_files += 1
                else:
                    print(f"âš ï¸  {json_file.name}: æ•°æ®ç»“æ„å¼‚å¸¸ï¼ˆæ— æœ‰æ•ˆæ–‡ç« ï¼‰")
                    invalid_files += 1
            else:
                print(f"âŒ {json_file.name}: æ ¹æ•°æ®ç±»å‹é”™è¯¯")
                invalid_files += 1
                
        except json.JSONDecodeError:
            print(f"âŒ {json_file.name}: JSONæ ¼å¼é”™è¯¯")
            invalid_files += 1
        except Exception as e:
            print(f"âŒ {json_file.name}: {e}")
            invalid_files += 1
    
    print(f"\nğŸ“ˆ **å®Œæ•´æ€§ç»Ÿè®¡**")
    print(f"   æœ‰æ•ˆæ–‡ä»¶: {valid_files}")
    print(f"   æ— æ•ˆæ–‡ä»¶: {invalid_files}")
    print(f"   æ•°æ®è´¨é‡: {valid_files/(valid_files+invalid_files)*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ†ææ•°æ®
        analyze_downloaded_data()
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        validate_data_integrity()
        
        # å¯¼å‡ºæ–‡ç« æ¸…å•
        try:
            export_article_list()
        except ImportError:
            print("\nâš ï¸  pandasæœªå®‰è£…ï¼Œè·³è¿‡CSVå¯¼å‡ºåŠŸèƒ½")
            print("   å¦‚éœ€å¯¼å‡ºCSVï¼Œè¯·è¿è¡Œ: pip install pandas")
        
        print("\nğŸ‰ æ•°æ®åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
